
from comfy_api.latest import io
import asyncio
import cv2
import numpy as np
import re
import torch


class VideoCutGroup(io.ComfyNode):
    @classmethod
    def define_schema(cls) -> io.Schema:
        return io.Schema(
            node_id="1hew_VideoCutGroup",
            display_name="Video Cut Group",
            category="1hewNodes/batch",
            inputs=[
                io.Image.Input("image"),
                io.Float.Input("threshold_base", default=0.8, min=0.0, max=1.0, step=0.01),
                io.Float.Input("threshold_range", default=0.05, min=0.01, max=0.2, step=0.01),
                io.Int.Input("threshold_count", default=2, min=1, max=10, step=1),
                io.String.Input("kernel", default="3, 7, 11"),
                io.Int.Input("min_frame_count", default=10, min=1, max=1000, step=1),
                io.Int.Input("max_frame_count", default=0, min=0, max=10000, step=1),
                io.Boolean.Input("fast", default=False),
                io.String.Input("add_frame", default="", optional=True),
                io.String.Input("delete_frame", default="", optional=True),
            ],
            outputs=[
                io.Image.Output(display_name="image"),
                io.Int.Output(display_name="group_total"),
                io.MultiType.Output(display_name="start_index", is_output_list=True),
                io.MultiType.Output(display_name="batch_count", is_output_list=True),
            ],
        )


    @classmethod
    async def execute(
        cls,
        image: torch.Tensor,
        threshold_base: float,
        threshold_range: float,
        threshold_count: int,
        kernel: str,
        min_frame_count: int,
        max_frame_count: int,
        fast: bool,
        add_frame: str,
        delete_frame: str,
    ) -> io.NodeOutput:
        B = int(image.shape[0])
        if B <= 1:
            return io.NodeOutput(image, 1, [0], [B])

        kernel_configs = cls.parse_custom_kernels(kernel)

        if fast:
            cut_points = cls.fast_mode_detection(
                image, threshold_base, min_frame_count, max_frame_count
            )
        else:
            images_np = image.detach().cpu().numpy()
            all_results = await cls.batch_detection_all_features_async(
                images_np,
                threshold_base,
                min_frame_count,
                max_frame_count,
                threshold_range,
                threshold_count,
                kernel_configs,
            )
            cut_points = cls.unified_voting_fusion(
                all_results, B, min_frame_count, max_frame_count
            )

        add_list = cls.parse_user_frames(add_frame)
        del_list = cls.parse_user_frames(delete_frame)
        s = set(cut_points)
        for a in add_list:
            if 0 <= a <= B:
                s.add(a)
        for d in del_list:
            if d in s and d != 0:
                s.remove(d)
        if 0 not in s:
            s.add(0)
        cut_points = sorted(list(s))
        cut_points = cls._apply_final_grouping_rules(
            cut_points, min_frame_count, max_frame_count, B
        )

        starts = cut_points
        counts = []
        for i in range(len(starts)):
            start = starts[i]
            if i == len(starts) - 1:
                cnt = max(0, B - start)
            else:
                cnt = max(0, starts[i + 1] - start)
            counts.append(cnt)

        selected = image[starts]
        return io.NodeOutput(selected, len(starts), starts, counts)

    @staticmethod
    def parse_user_frames(frame_string):
        """
        è§£æç”¨æˆ·è¾“å…¥çš„å¸§ç´¢å¼•å­—ç¬¦ä¸²ï¼Œæ”¯æŒé€—å·åˆ†éš”ï¼Œæ™ºèƒ½å¤„ç†ä¸­è‹±æ–‡é€—å·å’Œç©ºæ ¼
        """
        if not frame_string or not frame_string.strip():
            return []
        
        # æ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼
        normalized = re.sub(r'[ï¼Œ,]\s*', ',', frame_string.strip())
        
        # åˆ†å‰²å¹¶è½¬æ¢ä¸ºæ•´æ•°
        frame_indices = []
        for item in normalized.split(','):
            item = item.strip()
            if item and item.isdigit():
                frame_indices.append(int(item))
        
        return sorted(list(set(frame_indices)))  # å»é‡å¹¶æ’åº

    @staticmethod
    def parse_custom_kernels(kernel_string):
        """
        è§£æç”¨æˆ·è¾“å…¥çš„kernelé…ç½®å­—ç¬¦ä¸²ï¼Œæ”¯æŒé€—å·åˆ†éš”
        æ ¼å¼: "3,7,11" æˆ– "3,5,7,9,11,13,15"
        è¿”å›: [(kernel_size, sigma), ...] æ ¼å¼çš„åˆ—è¡¨
        """
        if not kernel_string or not kernel_string.strip():
            # å¦‚æœä¸ºç©ºï¼Œè¿”å›é»˜è®¤é…ç½®
            return [(3, 0.6), (7, 1.0), (11, 1.5)]
        
        # æ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼
        normalized = re.sub(r'[ï¼Œ,]\s*', ',', kernel_string.strip())
        
        # åˆ†å‰²å¹¶è½¬æ¢ä¸ºæ•´æ•°
        kernel_sizes = []
        for item in normalized.split(','):
            item = item.strip()
            if item and item.isdigit():
                size = int(item)
                # éªŒè¯kernelå¤§å°å¿…é¡»æ˜¯å¥‡æ•°ä¸”å¤§äºç­‰äº3
                if size >= 3 and size % 2 == 1:
                    kernel_sizes.append(size)
        
        # å»é‡å¹¶æ’åº
        kernel_sizes = sorted(list(set(kernel_sizes)))
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„kernelï¼Œè¿”å›é»˜è®¤é…ç½®
        if not kernel_sizes:
            return [(3, 0.6), (7, 1.0), (11, 1.5)]
        
        # ä¸ºæ¯ä¸ªkernelå¤§å°ç”Ÿæˆå¯¹åº”çš„sigmaå€¼
        # sigma = kernel_size * 0.2 (ç»éªŒå…¬å¼)
        kernel_configs = []
        for size in kernel_sizes:
            sigma = size * 0.2
            kernel_configs.append((size, sigma))
        
        return kernel_configs

    @staticmethod
    def simple_ssim(img1, img2, C1=0.01**2, C2=0.03**2):
        """
        ç®€æ˜“SSIMè®¡ç®—æ–¹æ³•ï¼Œç”¨äºå¿«é€Ÿæ¨¡å¼
        """
        # å¦‚æœæ˜¯å½©è‰²å›¾åƒï¼Œå…ˆè½¬ä¸ºç°åº¦
        if img1.shape[-1] == 3:
            img1 = 0.299 * img1[..., 0] + 0.587 * img1[..., 1] + 0.114 * img1[..., 2]
            img2 = 0.299 * img2[..., 0] + 0.587 * img2[..., 1] + 0.114 * img2[..., 2]
        
        # è®¡ç®—å‡å€¼
        mu1 = img1.mean()
        mu2 = img2.mean()
        
        # è®¡ç®—æ–¹å·®
        sigma1 = ((img1 - mu1) ** 2).mean()
        sigma2 = ((img2 - mu2) ** 2).mean()
        
        # è®¡ç®—åæ–¹å·®
        sigma12 = ((img1 - mu1) * (img2 - mu2)).mean()
        
        # è®¡ç®—SSIM
        ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / ((mu1 ** 2 + mu2 ** 2 + C1) * (sigma1 + sigma2 + C2))
        
        # ä¿è¯ç»“æœåœ¨0~1ä¹‹é—´
        return max(0.0, min(1.0, ssim.item() if hasattr(ssim, 'item') else float(ssim)))

    @staticmethod
    def preprocess_images_batch(images_np):
        """
        æ‰¹é‡é¢„å¤„ç†æ‰€æœ‰å›¾åƒï¼Œé¿å…é‡å¤è½¬æ¢
        """
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        if images_np.dtype != np.float32:
            images_np = images_np.astype(np.float32)
        
        # å¦‚æœå›¾åƒå€¼åœ¨ [0, 1] èŒƒå›´å†…ï¼Œè½¬æ¢ä¸º [0, 255] ä»¥ä¾¿SSIMè®¡ç®—
        if images_np.max() <= 1.0:
            images_np = images_np * 255.0
        
        # è½¬æ¢ä¸ºç°åº¦å›¾åƒä»¥æé«˜æ£€æµ‹æ•ˆæœ
        if len(images_np.shape) == 4 and images_np.shape[3] == 3:
            # RGBè½¬ç°åº¦ï¼š0.299*R + 0.587*G + 0.114*B
            images_np = np.dot(images_np[..., :3], [0.299, 0.587, 0.114])
        elif len(images_np.shape) == 4 and images_np.shape[3] == 1:
            # å·²ç»æ˜¯å•é€šé“ï¼Œå»æ‰æœ€åä¸€ä¸ªç»´åº¦
            images_np = images_np.squeeze(-1)
        
        return images_np

    @staticmethod
    def batch_calculate_ssim_matrix(processed_images, kernel_configs):
        """
        æ‰¹é‡è®¡ç®—æ‰€æœ‰ç›¸é‚»å¸§çš„SSIMå€¼çŸ©é˜µï¼Œä½¿ç”¨å›ºå®šçš„æ ¸é…ç½®å’Œæ¨¡ç³Šæ¨¡å¼
        """
        B = processed_images.shape[0]
        if B <= 1:
            return {}
        
        ssim_matrix = {}
        
        # ä¸ºæ¯ä¸ªæ ¸é…ç½®è®¡ç®—æ¨¡ç³ŠSSIM
        for kernel_idx, kernel_config in enumerate(kernel_configs):
            kernel_size, sigma = kernel_config
            ssim_values = np.zeros(B - 1, dtype=np.float32)
            
            # è®¡ç®—æ‰€æœ‰ç›¸é‚»å¸§çš„æ¨¡ç³ŠSSIM
            for i in range(B - 1):
                ssim_val = VideoCutGroup._blur_pixel_ssim(
                    processed_images[i], processed_images[i + 1], kernel_size, sigma
                )
                ssim_values[i] = ssim_val
            
            ssim_matrix[kernel_idx] = ssim_values
        
        return ssim_matrix

    @staticmethod
    async def batch_calculate_ssim_matrix_async(processed_images, kernel_configs):
        B = processed_images.shape[0]
        if B <= 1:
            return {}
        async def task(idx, config):
            kernel_size, sigma = config
            ssim_values = np.zeros(B - 1, dtype=np.float32)
            def calc():
                for i in range(B - 1):
                    s = VideoCutGroup._blur_pixel_ssim(
                        processed_images[i], processed_images[i + 1], kernel_size, sigma
                    )
                    ssim_values[i] = s
                return ssim_values
            values = await asyncio.to_thread(calc)
            return idx, values
        tasks = [task(i, kernel_configs[i]) for i in range(len(kernel_configs))]
        results = await asyncio.gather(*tasks)
        ssim_matrix = {idx: values for idx, values in results}
        return ssim_matrix

    @staticmethod
    def _blur_pixel_ssim(img1, img2, kernel_size, sigma):
        """æ¨¡ç³Šåƒç´ SSIMè®¡ç®—ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        ksize = (kernel_size, kernel_size)
        img1_blur = cv2.GaussianBlur(img1, ksize, sigma)
        img2_blur = cv2.GaussianBlur(img2, ksize, sigma)
        
        # è®¡ç®—å‡å€¼
        mu1 = cv2.boxFilter(img1_blur, -1, (kernel_size, kernel_size))
        mu2 = cv2.boxFilter(img2_blur, -1, (kernel_size, kernel_size))
        
        mu1_sq = mu1 * mu1
        mu2_sq = mu2 * mu2
        mu1_mu2 = mu1 * mu2
        
        # è®¡ç®—æ–¹å·®å’Œåæ–¹å·®
        sigma1_sq = cv2.boxFilter(img1_blur * img1_blur, -1, (kernel_size, kernel_size)) - mu1_sq
        sigma2_sq = cv2.boxFilter(img2_blur * img2_blur, -1, (kernel_size, kernel_size)) - mu2_sq
        sigma12 = cv2.boxFilter(img1_blur * img2_blur, -1, (kernel_size, kernel_size)) - mu1_mu2
        
        # SSIMå¸¸æ•°
        C1 = (0.01) ** 2
        C2 = (0.03) ** 2
        
        # è®¡ç®—SSIM
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        
        return float(np.mean(ssim_map))

    @staticmethod
    def generate_dynamic_thresholds(threshold_base, threshold_range=0.05, threshold_count=2):
        """
        ç”ŸæˆåŠ¨æ€æ•°é‡çš„é˜ˆå€¼
        threshold_count=1: åªä½¿ç”¨threshold_base
        threshold_count=2: èŒƒå›´ä¸¤ç«¯ [base-range, base+range]
        threshold_count=3: ä¸¤ç«¯+ä¸­é—´ [base-range, base, base+range]
        threshold_count=4+: åœ¨èŒƒå›´å†…å‡åŒ€åˆ†å¸ƒ
        """
        if threshold_count == 1:
            # åªä½¿ç”¨åŸºç¡€é˜ˆå€¼
            thresholds = [threshold_base]
        elif threshold_count == 2:
            # èŒƒå›´ä¸¤ç«¯
            thresholds = [
                threshold_base - threshold_range,  # ä¸‹é™
                threshold_base + threshold_range   # ä¸Šé™
            ]
        else:
            # 3ä¸ªæˆ–æ›´å¤šï¼šåœ¨èŒƒå›´å†…å‡åŒ€åˆ†å¸ƒ
            min_threshold = threshold_base - threshold_range
            max_threshold = threshold_base + threshold_range
            
            if threshold_count == 3:
                # ç‰¹æ®Šå¤„ç†ï¼šä¸¤ç«¯+ä¸­é—´
                thresholds = [min_threshold, threshold_base, max_threshold]
            else:
                # 4ä¸ªæˆ–æ›´å¤šï¼šå‡åŒ€åˆ†å¸ƒ
                step = (max_threshold - min_threshold) / (threshold_count - 1)
                thresholds = [min_threshold + i * step for i in range(threshold_count)]
        
        # ç¡®ä¿é˜ˆå€¼åœ¨åˆç†èŒƒå›´å†…
        thresholds = [max(0.0, min(1.0, t)) for t in thresholds]
        
        return sorted(thresholds)

    @staticmethod
    def optimized_single_threshold_detection(ssim_matrix, user_threshold, kernel_idx, 
                                           min_frame_count, max_frame_count, total_frames):
        """
        åŸºäºé¢„è®¡ç®—SSIMçŸ©é˜µçš„çº¯ç²¹é˜ˆå€¼æ£€æµ‹æ–¹æ³•
        ä¿®æ­£é˜ˆå€¼é€»è¾‘ï¼šç”¨æˆ·é˜ˆå€¼è¶Šå¤§ï¼Œæ£€æµ‹è¶Šä¸¥æ ¼ï¼Œç”»é¢è¶Šå°‘
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•åªè¿›è¡Œçº¯ç²¹çš„é˜ˆå€¼æ£€æµ‹ï¼Œä¸åº”ç”¨åˆ†ç»„è§„åˆ™
        åˆ†ç»„è§„åˆ™åº”è¯¥åœ¨æ‰€æœ‰é˜ˆå€¼æ£€æµ‹å®Œæˆåï¼Œåœ¨æœ€ç»ˆåˆå¹¶é˜¶æ®µç»Ÿä¸€åº”ç”¨
        """
        B = total_frames
        if B <= 1:
            return [0]
        
        # è·å–å¯¹åº”çš„SSIMå€¼æ•°ç»„
        if kernel_idx not in ssim_matrix:
            return [0]
        
        ssim_values = ssim_matrix[kernel_idx]
        
        # çº¯ç²¹çš„é˜ˆå€¼æ£€æµ‹ï¼šæ‰¾å‡ºæ‰€æœ‰æ»¡è¶³é˜ˆå€¼æ¡ä»¶çš„ç¡¬åˆ‡ç‚¹
        threshold_cuts = [0]  # ç¬¬ä¸€ç»„æ€»æ˜¯ä»0å¼€å§‹
        for i in range(len(ssim_values)):
            ssim_val = ssim_values[i]
            # ç›´æ¥æ¯”è¾ƒï¼š(1-ssim)å¤§äºç”¨æˆ·é˜ˆå€¼æ—¶ï¼Œè®¤ä¸ºæ˜¯ç¡¬åˆ‡
            if (1.0 - ssim_val) > user_threshold:
                cut_point = i + 1  # ç¡¬åˆ‡åçš„å¸§ä½œä¸ºæ–°ç»„çš„èµ·å§‹
                if cut_point < B and cut_point not in threshold_cuts:
                    threshold_cuts.append(cut_point)
        
        return threshold_cuts


    @staticmethod
    def batch_detection_all_features(images_np, threshold_base, min_frame_count, max_frame_count, threshold_range=0.05, threshold_count=2, kernel_configs=None):
        """
        æ‰¹é‡æ£€æµ‹æ‰€æœ‰ç‰¹å¾ç»„åˆï¼Œä½¿ç”¨å›ºå®šçš„æ ¸é…ç½®å’Œå‚æ•°
        """
        total_frames = len(images_np)
        
        if total_frames < 2:
            return [[0]]
        
        # é¢„å¤„ç†å›¾åƒ
        processed_images = VideoCutGroup.preprocess_images_batch(images_np)
        
        # æ‰¹é‡è®¡ç®—SSIMçŸ©é˜µ
        ssim_matrix = VideoCutGroup.batch_calculate_ssim_matrix(processed_images, kernel_configs)
        
        # ç”ŸæˆåŠ¨æ€æ•°é‡çš„é˜ˆå€¼
        user_thresholds = VideoCutGroup.generate_dynamic_thresholds(threshold_base, threshold_range, threshold_count)
        
        # æ‰“å°æ£€æµ‹ä»»åŠ¡æ¦‚è§ˆ
        print()
        print("=== ğŸš€ VideoCutGroup å¤šæ ¸æ¨¡ç³Šæ¨¡å¼æ£€æµ‹ å¯åŠ¨ ===")
        print(f"threshold: {[f'{t:.3f}' for t in user_thresholds]}")
        kernel_list = [str(k[0]) for k in kernel_configs]
        print(f"kernel: [{','.join(kernel_list)}]")
        print()
        
        total_groups = len(kernel_configs) * len(user_thresholds)
        print(f"ğŸ“ˆ {total_groups} ç»„æ£€æµ‹ä»»åŠ¡è¯¦æƒ…")
        
        # å¯¹æ¯ä¸ªæ ¸å’Œæ¯ä¸ªé˜ˆå€¼è¿›è¡Œæ£€æµ‹
        all_detection_results = []
        group_num = 1
        
        for kernel_idx in range(len(kernel_configs)):
            kernel_size, sigma = kernel_configs[kernel_idx]
            
            for user_threshold in user_thresholds:
                # ä½¿ç”¨ä¼˜åŒ–çš„æ£€æµ‹æ–¹æ³•
                result = VideoCutGroup.optimized_single_threshold_detection(
                    ssim_matrix, user_threshold, kernel_idx, min_frame_count, max_frame_count, total_frames
                )
                all_detection_results.append(result)
                
                # è·å–é˜ˆå€¼è¯¦ç»†ä¿¡æ¯ç”¨äºæ—¥å¿— - åŸºäºå®é™…æ£€æµ‹ç»“æœ
                threshold_details = []
                if kernel_idx in ssim_matrix and len(result) > 1:
                    ssim_values = ssim_matrix[kernel_idx]
                    # éå†å®é™…æ£€æµ‹åˆ°çš„åˆ‡ç‚¹ï¼ˆæ’é™¤èµ·å§‹ç‚¹0ï¼‰
                    for cut_point in result[1:]:  # è·³è¿‡èµ·å§‹ç‚¹0
                        if cut_point > 0 and cut_point <= len(ssim_values):
                            # åˆ‡ç‚¹å¯¹åº”çš„æ˜¯å‰ä¸€å¸§ä¸å½“å‰å¸§çš„æ¯”è¾ƒ
                            ssim_val = ssim_values[cut_point - 1]
                            threshold_val = 1.0 - ssim_val
                            threshold_details.append(f"{cut_point}:{threshold_val:.3f}")
                
                # æ ¼å¼åŒ–æ—¥å¿—è¾“å‡ºï¼ˆæ’é™¤èµ·å§‹ç‚¹0ï¼‰
                actual_cut_points = len(result) - 1 if result and result[0] == 0 else len(result)
                print(f"ğŸ” ç¬¬{group_num}ç»„ï¼š threshold={user_threshold:.3f}ï¼Œkernel = {kernel_size}")
                print(f"- æ£€æµ‹åˆ‡ç‚¹ï¼š{actual_cut_points} ä¸ª [indexï¼šthreshold]")
                if threshold_details:
                    print(f"- [{', '.join(threshold_details)}]")
                print()
                
                group_num += 1
        
        # å­˜å‚¨æ£€æµ‹ç»“æœç”¨äºåç»­æ±‡æ€»
        # æ‘˜è¦ç”±æ‰“å°è¾“å‡ºè¡¨ç¤º
        
        return all_detection_results

    @staticmethod
    async def batch_detection_all_features_async(images_np, threshold_base, min_frame_count, max_frame_count, threshold_range=0.05, threshold_count=2, kernel_configs=None):
        total_frames = len(images_np)
        if total_frames < 2:
            return [[0]]
        processed_images = VideoCutGroup.preprocess_images_batch(images_np)
        ssim_matrix = await VideoCutGroup.batch_calculate_ssim_matrix_async(processed_images, kernel_configs)
        user_thresholds = VideoCutGroup.generate_dynamic_thresholds(threshold_base, threshold_range, threshold_count)
        detect_tasks = []
        for kernel_idx in range(len(kernel_configs)):
            for user_threshold in user_thresholds:
                def detect():
                    return VideoCutGroup.optimized_single_threshold_detection(
                        ssim_matrix, user_threshold, kernel_idx, min_frame_count, max_frame_count, total_frames
                    )
                detect_tasks.append(asyncio.to_thread(detect))
        results = await asyncio.gather(*detect_tasks)
        return results

    @staticmethod
    def unified_voting_fusion(all_detection_results, total_frames, min_frame_count=10, max_frame_count=0):
        """
        ç»Ÿä¸€èåˆæ–¹æ³•ï¼Œæ•´åˆæ‰€æœ‰æ£€æµ‹ç»“æœå¹¶åº”ç”¨åˆ†ç»„è§„åˆ™
        
        é‡è¦ï¼šåœ¨æ­¤é˜¶æ®µç»Ÿä¸€åº”ç”¨min_frame_countå’Œmax_frame_countè§„åˆ™ï¼Œ
        ç¡®ä¿æ‰€æœ‰é˜ˆå€¼ç»„åˆéƒ½ä½¿ç”¨ç›¸åŒçš„åˆ†ç»„ç­–ç•¥
        """
        if not all_detection_results:
            return [0]
        
        # æ‰“å°æœ€ç»ˆæ£€æµ‹ç»“æœæ±‡æ€»
        print()
        print("âœ… æœ€ç»ˆæ£€æµ‹ç»“æœ")
        
        # æ”¶é›†æ‰€æœ‰åˆ‡ç‚¹ï¼ˆå»é‡ï¼‰
        all_cut_points = set([0])  # èµ·å§‹å¸§
        for result in all_detection_results:
            for frame in result[1:]:  # è·³è¿‡èµ·å§‹å¸§0
                all_cut_points.add(frame)
        
        # æ’åº
        raw_cut_points = sorted(list(all_cut_points))
        
        # æ˜¾ç¤ºåˆå¹¶å‰çš„ç»“æœ
        print(f"åˆå¹¶æ£€æµ‹ç»“æœï¼š{len(raw_cut_points)} ä¸ª")
        print(f"{raw_cut_points}")
        print()
        
        # åº”ç”¨åˆ†ç»„è§„åˆ™
        final_cut_points = VideoCutGroup._apply_final_grouping_rules(raw_cut_points, min_frame_count, max_frame_count, total_frames)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print(f"min_frame_count={min_frame_count}, max_frame_count={max_frame_count} ï¼Œåˆ†ç»„è§„åˆ™å¤„ç†åï¼š{len(final_cut_points)} ä¸ª")
        print(f"{final_cut_points}")
        print()
        
        return final_cut_points
    
    @staticmethod
    def _apply_final_grouping_rules(cut_points, min_frame_count, max_frame_count, total_frames):
        """
        åœ¨æœ€ç»ˆé˜¶æ®µåº”ç”¨åˆ†ç»„è§„åˆ™
        """
        if not cut_points or len(cut_points) <= 1:
            return [0]
        
        # åº”ç”¨min_frame_countè§„åˆ™ï¼šåˆå¹¶è¿‡è¿‘çš„åˆ‡ç‚¹
        filtered_points = [cut_points[0]]  # ä¿ç•™èµ·å§‹ç‚¹0
        
        for point in cut_points[1:]:
            if point - filtered_points[-1] >= min_frame_count:
                filtered_points.append(point)
            # å¦‚æœè·ç¦»å¤ªè¿‘ï¼Œè·³è¿‡è¿™ä¸ªåˆ‡ç‚¹
        
        # åº”ç”¨max_frame_countè§„åˆ™ï¼šæ‹†åˆ†è¿‡é•¿çš„æ®µ
        if max_frame_count > 0:
            final_points = [0]
            
            for i in range(1, len(filtered_points)):
                start = filtered_points[i-1]
                end = filtered_points[i]
                segment_length = end - start
                
                # å¦‚æœæ®µé•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œéœ€è¦æ‹†åˆ†
                if segment_length > max_frame_count:
                    # åœ¨è¿™ä¸ªæ®µå†…æŒ‰max_frame_counté—´éš”æ’å…¥åˆ‡ç‚¹
                    current = start
                    while current + max_frame_count < end:
                        current += max_frame_count
                        final_points.append(current)
                
                # æ·»åŠ åŸå§‹åˆ‡ç‚¹
                final_points.append(end)
            
            # å¤„ç†æœ€åä¸€æ®µï¼ˆåˆ°è§†é¢‘ç»“å°¾ï¼‰
            if len(filtered_points) > 0:
                last_point = filtered_points[-1]
                if last_point < total_frames:
                    remaining_length = total_frames - last_point
                    if remaining_length > max_frame_count:
                        current = last_point
                        while current + max_frame_count < total_frames:
                            current += max_frame_count
                            final_points.append(current)
            
            return sorted(list(set(final_points)))
        else:
            return filtered_points

    @staticmethod
    def sequential_detection(images, threshold_base, min_frame_count, max_frame_count, threshold_range=0.05, threshold_count=2, kernel_configs=None):
        """
        åºåˆ—æ£€æµ‹æ–¹æ³•ï¼Œæ ¹æ®å‚æ•°é…ç½®è¿›è¡Œè§†é¢‘ç¡¬åˆ‡æ£€æµ‹
        """
        # è½¬æ¢å›¾åƒæ ¼å¼
        if hasattr(images, 'cpu'):
            images_np = images.cpu().numpy()
        else:
            images_np = images
        
        # æ‰¹é‡æ£€æµ‹æ‰€æœ‰ç‰¹å¾ç»„åˆ
        all_detection_results = VideoCutGroup.batch_detection_all_features(
            images_np, threshold_base, min_frame_count, max_frame_count, threshold_range, threshold_count, kernel_configs
        )
        
        # ç»Ÿä¸€æŠ•ç¥¨èåˆ
        final_split_points = VideoCutGroup.unified_voting_fusion(all_detection_results, len(images_np), min_frame_count, max_frame_count)
        
        return final_split_points

    @staticmethod
    def fast_mode_detection(images, threshold_base, min_frame_count, max_frame_count):
        """
        å¿«é€Ÿæ¨¡å¼æ£€æµ‹ï¼Œä½¿ç”¨ç®€åŒ–çš„SSIMè®¡ç®—æ–¹æ³•
        æ³¨æ„ï¼šè¿™é‡Œçš„threshold_baseå·²ç»ç»è¿‡1-å¤„ç†ï¼Œéœ€è¦è½¬æ¢å›åŸå§‹é˜ˆå€¼é€»è¾‘
        """
        if hasattr(images, 'cpu'):
            images_np = images.cpu().numpy()
        else:
            images_np = images
        B = int(images_np.shape[0])
        if B < 2:
            return [0]

        threshold = float(max(0.0, min(1.0, threshold_base)))
        processed = VideoCutGroup.preprocess_images_batch(images_np)

        ssim_list = []
        for i in range(B - 1):
            ssim_val = VideoCutGroup.simple_ssim(processed[i], processed[i + 1])
            ssim_list.append(ssim_val)

        cut_points = [0]
        for i, ssim_val in enumerate(ssim_list):
            if (1.0 - float(ssim_val)) > threshold:
                cp = i + 1
                if cp < B:
                    cut_points.append(cp)

        cut_points = sorted(list(set(cut_points)))
        final_points = VideoCutGroup._apply_final_grouping_rules(
            cut_points, min_frame_count, max_frame_count, B
        )
        return final_points


    def apply_user_modifications(self, cut_points, add_frame, delete_frame, total_frames):
        """
        åº”ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„æ·»åŠ å’Œåˆ é™¤å¸§ä¿®æ”¹
        """
        # è§£æç”¨æˆ·è¾“å…¥
        add_frames = self.parse_user_frames(add_frame)
        delete_frames = self.parse_user_frames(delete_frame)
        
        # åº”ç”¨ä¿®æ”¹
        modified_cut_points = list(cut_points)
        
        # è®°å½•å®é™…æ·»åŠ å’Œåˆ é™¤çš„å¸§
        actually_added = []
        actually_deleted = []
        
        # æ·»åŠ ç”¨æˆ·æŒ‡å®šçš„å¸§
        for frame in add_frames:
            if 0 <= frame < total_frames and frame not in modified_cut_points:
                modified_cut_points.append(frame)
                actually_added.append(frame)
        
        # åˆ é™¤ç”¨æˆ·æŒ‡å®šçš„å¸§ï¼ˆä½†ä¿ç•™èµ·å§‹å¸§0ï¼‰
        for frame in delete_frames:
            if frame in modified_cut_points and frame != 0:
                modified_cut_points.remove(frame)
                actually_deleted.append(frame)
        
        # æ‰“å°ç”¨æˆ·è®¾å®šçš„æ‰€æœ‰æ·»åŠ å’Œåˆ é™¤ä¿¡æ¯ï¼ˆä¸æ˜¯è¿‡æ»¤åçš„ï¼‰
        if add_frames:
            print(f"â• ç”¨æˆ·æ·»åŠ å¸§: {add_frames}")
        if delete_frames:
            print(f"â– ç”¨æˆ·åˆ é™¤å¸§: {delete_frames}")
        
        # æ’åºå¹¶è¿”å›
        final_cut_points = sorted(list(set(modified_cut_points)))
        
        if add_frames or delete_frames:
            print(f"ğŸ”§ åæœŸå¢å‡å¸§å¤„ç†åï¼š{len(final_cut_points)} ä¸ª")
            print(f"{final_cut_points}")
        
        return final_cut_points